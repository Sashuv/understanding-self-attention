{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Manual Self-Attention Implementation in PyTorch – Focusing on a Single Token's Perspective"
      ],
      "metadata": {
        "id": "_8Qi06jWPDQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "gmkT3GeKL_SX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create a random input token matrix inputToken with shape [5, 4]. Each row represents a token in 4D space."
      ],
      "metadata": {
        "id": "udvl3T-VMzST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d_in = 4\n",
        "no_of_tokens = 5\n",
        "# hyperparameter\n",
        "d_out = 3\n",
        "\n",
        "inputToken = torch.rand(no_of_tokens,d_in)\n",
        "print(inputToken)\n",
        "print(\"Shape:\", inputToken.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COcl_MVKh9Qz",
        "outputId": "dbbf62a0-bd7a-406b-8f9a-f0ddf90337a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5159, 0.4220, 0.5786, 0.9455],\n",
            "        [0.8057, 0.6775, 0.6087, 0.6179],\n",
            "        [0.6932, 0.4354, 0.0353, 0.1908],\n",
            "        [0.9268, 0.5299, 0.0950, 0.5789],\n",
            "        [0.9131, 0.0275, 0.1634, 0.3009]])\n",
            "Shape: torch.Size([5, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example**: Picking One Token"
      ],
      "metadata": {
        "id": "D2Z4QoICM5Pz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pick out a single token\n",
        "stoken = inputToken[2]\n",
        "stoken.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buXEEK0EMQVN",
        "outputId": "98cf3df1-50f7-498e-fa33-302be458a3b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4])"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Learnable Parameters:** Query, Key, and Value Matrices\n",
        "In self-attention, every token is transformed into three vectors:\n",
        "\n",
        "**Query**: What the token is asking about others\n",
        "\n",
        "**Key**: What others contain (like tags or metadata)\n",
        "\n",
        "**Value**: The actual content to be aggregated"
      ],
      "metadata": {
        "id": "JJanKstsNAP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# random seed initialization\n",
        "torch.manual_seed(123)\n",
        "# defining query, key and value matrix\n",
        "QueryM = nn.Linear(d_in, d_out)\n",
        "KeyM = nn.Linear(d_in, d_out)\n",
        "ValueM = nn.Linear(d_in, d_out)"
      ],
      "metadata": {
        "id": "V4HHZCzBMWV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Query Matrix: \",QueryM)\n",
        "print(\"------------\")\n",
        "print(\"Key Matrix: \",KeyM)\n",
        "print(\"------------\")\n",
        "print(\"Value Matrix: \",ValueM)\n",
        "print(\"------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zcCNfCCNNUZ",
        "outputId": "164b08ff-77c1-4090-fe91-6deb1980a24e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query Matrix:  Linear(in_features=4, out_features=3, bias=True)\n",
            "------------\n",
            "Key Matrix:  Linear(in_features=4, out_features=3, bias=True)\n",
            "------------\n",
            "Value Matrix:  Linear(in_features=4, out_features=3, bias=True)\n",
            "------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Single Token Attention"
      ],
      "metadata": {
        "id": "55e-e5opNYSg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We transform one token into its **query**, **key**, and **value**."
      ],
      "metadata": {
        "id": "sca83brwNhp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query3 = QueryM(stoken)\n",
        "key3 = KeyM(stoken)\n",
        "value3 = ValueM(stoken)"
      ],
      "metadata": {
        "id": "1y514rEENQIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijV1hTRzPvfv",
        "outputId": "10bef344-6330-4370-b8f8-29f288c00485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.5313, -0.5278, -0.2748], grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# finding keys & values for all inputs\n",
        "keys = KeyM(inputToken)\n",
        "values = ValueM(inputToken)"
      ],
      "metadata": {
        "id": "0E4_825dOiMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keys"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-ujACsdPd-0",
        "outputId": "6538cf28-1d9c-42ba-b0a7-f5a31747ba5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.2236,  0.8145, -0.4259],\n",
              "        [ 0.1462,  0.9094, -0.2659],\n",
              "        [ 0.1122,  0.6939, -0.2615],\n",
              "        [ 0.0270,  0.8234, -0.2469],\n",
              "        [ 0.2751,  0.6120, -0.0675]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wUm4pGyPew3",
        "outputId": "6da3cbbf-1855-4ee4-fd90-a773c7ec1707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.5962,  0.2799, -0.5147],\n",
              "        [ 0.7200,  0.4179, -0.5233],\n",
              "        [ 0.4013,  0.6908, -0.3236],\n",
              "        [ 0.6165,  0.7007, -0.5124],\n",
              "        [ 0.4484,  0.7392, -0.4560]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attention Weights Calculation\n"
      ],
      "metadata": {
        "id": "-1QUcaRRNqgB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This gives raw **attention scores** for each token with respect to the query."
      ],
      "metadata": {
        "id": "KMwDG3l2Nn31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights = query3 @ keys.T\n",
        "attention_weights"
      ],
      "metadata": {
        "id": "pks2WB1OgPoZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00e592b4-ec5e-4417-b5ac-d6a48353c963"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.4316, -0.4845, -0.3540, -0.3810, -0.4506],\n",
              "       grad_fn=<SqueezeBackward4>)"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We scale the scores (divide by** √d_in**) to prevent overly large dot products and apply softmax to normalize them into probabilities."
      ],
      "metadata": {
        "id": "Dd4pIS-0N1rV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights = torch.softmax(attention_weights / d_in**(1/2), dim =-1)\n",
        "attention_weights"
      ],
      "metadata": {
        "id": "v5jN4GN0ihrr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "044c1773-b442-4f16-d1da-e23a248909b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1988, 0.1936, 0.2067, 0.2039, 0.1969], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(attention_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1fr0EGqjGFP",
        "outputId": "f772bec8-0338-4ea7-bb13-341ce73c3044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0000, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the weighted sum of value vectors — the output of attention for token 3."
      ],
      "metadata": {
        "id": "TaloYNiAOBk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context_vector_3 = attention_weights @ values\n",
        "context_vector_3"
      ],
      "metadata": {
        "id": "H-nVbAEnE2UF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28203972-25a2-4532-e3e1-dbcc0fd6fb57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.5549,  0.5678, -0.4649], grad_fn=<SqueezeBackward4>)"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Self-Attention as a PyTorch Class – Computing Attention Across All Tokens"
      ],
      "metadata": {
        "id": "kns3l-mLGNJV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This class encapsulates the **entire** self-attention mechanism for a given input sequence."
      ],
      "metadata": {
        "id": "dCoKbut-OqEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "torch.manual_seed(123)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkIrTC8hGU-z",
        "outputId": "e83ef048-a760-49c0-885c-3d2d4b9b5f0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7d5fe87d6870>"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "source": [
        "import torch.nn as nn\n",
        "torch.manual_seed(123)\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, no_of_tokens, d_in, d_out):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.QueryM = nn.Linear(d_in, d_out)\n",
        "        self.KeyM   = nn.Linear(d_in, d_out)\n",
        "        self.ValueM = nn.Linear(d_in, d_out)\n",
        "\n",
        "    def forward(self, inputToken):\n",
        "        queries = self.QueryM(inputToken)\n",
        "        keys = self.KeyM(inputToken)\n",
        "        values = self.ValueM(inputToken)\n",
        "        attention_weights = queries @ keys.T\n",
        "        attention_weights = torch.softmax(attention_weights / d_in**0.5, dim=-1)\n",
        "        context_vector = attention_weights @ values\n",
        "        return context_vector, queries, keys, values, attention_weights"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "QwhMkq104N15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can now instantiate and run it:"
      ],
      "metadata": {
        "id": "9sDYSKY5O4sI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "att = SelfAttention(5, 4, 3)\n",
        "context_vector, queries, keys, values, attention_weights = att(inputToken)\n",
        "print(\"Context Vector:\\n\", context_vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1KgzIQOGRtH",
        "outputId": "798c0911-12f7-42f1-beef-1c9d37d4593e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context Vector:\n",
            " tensor([[ 0.5522,  0.5712, -0.4637],\n",
            "        [ 0.5531,  0.5700, -0.4640],\n",
            "        [ 0.5549,  0.5678, -0.4649],\n",
            "        [ 0.5535,  0.5694, -0.4642],\n",
            "        [ 0.5536,  0.5687, -0.4642]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    }
  ]
}